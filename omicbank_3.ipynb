{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b021310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:72: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:72: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\91939\\AppData\\Local\\Temp\\ipykernel_20228\\1646281781.py:14: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  with open(\".\\codes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
      "C:\\Users\\91939\\AppData\\Local\\Temp\\ipykernel_20228\\1646281781.py:72: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df = pd.read_excel(\".\\Diagnoses_list.xlsx\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ICD-10 metadata processed.\n",
      "WARNING:tensorflow:From C:\\Users\\91939\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df94422f23d94e55ab5400a0e08d9865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS index created.\n",
      "‚úÖ ICD-10 mapping with hybrid retrieval complete!\n",
      "üìä SUMMARY REPORT:\n",
      "   Total diagnoses mapped: 3171\n",
      "   High confidence matches: 111 (3.5%)\n",
      "   Medium confidence matches: 49 (1.5%)\n",
      "   Low confidence matches: 3011 (95.0%)\n",
      "üìÅ File saved ‚Üí final_icd10_mapped_output_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Step 0: Setup\n",
    "# =============================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================\n",
    "# Step 1: Preprocess ICD-10 Metadata from .txt\n",
    "# =============================================\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(\".\\codes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "entries = []\n",
    "for line in lines:\n",
    "    parts = line.strip().split(None, 4)\n",
    "    if len(parts) == 5:\n",
    "        _, code, _, short_desc, long_desc = parts\n",
    "        entries.append({\n",
    "            \"code\": code,\n",
    "            \"short_description\": short_desc.strip(),\n",
    "            \"long_description\": long_desc.strip()\n",
    "        })\n",
    "\n",
    "chunks = [f\"ICD Code: {e['code']}. Description: {e['long_description']}\" for e in entries]\n",
    "codes = [e['code'] for e in entries]\n",
    "descriptions = [e['long_description'] for e in entries]\n",
    "\n",
    "os.makedirs(\"icd10_kb\", exist_ok=True)\n",
    "with open(\"icd10_kb/icd_chunks_3.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, indent=2)\n",
    "with open(\"icd10_kb/icd_codes_3.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(codes, f, indent=2)\n",
    "with open(\"icd10_kb/icd_descriptions_3.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(descriptions, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ ICD-10 metadata processed.\")\n",
    "\n",
    "# =======================================================\n",
    "# Step 2: Create Embedding Index using Sentence-BERT + FAISS\n",
    "# =======================================================\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"pritamdeka/S-PubMedBert-MS-MARCO\"\n",
    "embedder = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "embeddings = embedder.encode(chunks, show_progress_bar=True)\n",
    "dim = embeddings[0].shape[0]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.array(embeddings))\n",
    "faiss.write_index(index, \"icd10_index_3.faiss\")\n",
    "print(\"‚úÖ FAISS index created.\")\n",
    "\n",
    "# ===================================================\n",
    "# Step 3: Hybrid Keyword + Semantic Retriever Mapping\n",
    "# ===================================================\n",
    "import ast\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Load assets with _3 suffix\n",
    "with open(\"icd10_kb/icd_chunks_3.json\", \"r\") as f: icd_chunks = json.load(f)\n",
    "with open(\"icd10_kb/icd_codes_3.json\", \"r\") as f: icd_codes = json.load(f)\n",
    "with open(\"icd10_kb/icd_descriptions_3.json\", \"r\") as f: icd_descs = json.load(f)\n",
    "index = faiss.read_index(\"icd10_index_3.faiss\")\n",
    "\n",
    "# Load patient diagnoses file\n",
    "df = pd.read_excel(\".\\Diagnoses_list.xlsx\")\n",
    "results = []\n",
    "\n",
    "for row_id, raw in enumerate(df[\"Diagnoses_list\"].dropna()):\n",
    "    try:\n",
    "        diagnoses = ast.literal_eval(raw)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for diag in diagnoses:\n",
    "        # --- Step 1: Keyword Match ---\n",
    "        keyword_result = process.extractOne(diag, icd_descs, scorer=fuzz.token_sort_ratio, score_cutoff=85, processor=None)\n",
    "\n",
    "        if keyword_result:\n",
    "            match, score, idx = keyword_result\n",
    "            code = icd_codes[idx]\n",
    "            confidence = \"High\" if score >= 95 else \"Medium\"\n",
    "            justification = f\"Keyword match with score {score}/100. Confidence: {confidence}. Found similar phrase in ICD description.\"\n",
    "            alternatives = \"\"\n",
    "        else:\n",
    "            # --- Step 2: Semantic Search ---\n",
    "            emb = embedder.encode([diag])\n",
    "            D, I = index.search(np.array(emb), k=3)\n",
    "            idx = I[0][0]\n",
    "            alt = [(icd_codes[I[0][j]], icd_descs[I[0][j]], float(D[0][j])) for j in range(3)]\n",
    "            code = icd_codes[idx]\n",
    "            confidence = \"Low\" if D[0][0] > 0.8 else \"Medium\"\n",
    "            justification = f\"Semantic match using Sentence-BERT. Distance: {D[0][0]:.3f}. Confidence: {confidence}. No direct keyword match found above threshold.\"\n",
    "            alternatives = f\"{alt[1][0]} (distance: {alt[1][2]:.3f}), {alt[2][0]} (distance: {alt[2][2]:.3f})\"\n",
    "\n",
    "        results.append({\n",
    "            \"row_id\": row_id,\n",
    "            \"original_diagnosis\": diag,\n",
    "            \"matched_icd_code\": code,\n",
    "            \"matched_description\": icd_descs[idx],\n",
    "            \"confidence_level\": confidence,\n",
    "            \"justification\": justification,\n",
    "            \"alternative_codes\": alternatives\n",
    "        })\n",
    "\n",
    "# ===========================================\n",
    "# Step 4: Save Mapped Results with Justification\n",
    "# ===========================================\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_excel(\"final_icd10_mapped_output_3.xlsx\", index=False)\n",
    "\n",
    "# Generate summary report\n",
    "total_mappings = len(df_results)\n",
    "high_confidence = len(df_results[df_results['confidence_level'] == 'High'])\n",
    "medium_confidence = len(df_results[df_results['confidence_level'] == 'Medium'])\n",
    "low_confidence = len(df_results[df_results['confidence_level'] == 'Low'])\n",
    "\n",
    "print(\"‚úÖ ICD-10 mapping with hybrid retrieval complete!\")\n",
    "print(f\"üìä SUMMARY REPORT:\")\n",
    "print(f\"   Total diagnoses mapped: {total_mappings}\")\n",
    "print(f\"   High confidence matches: {high_confidence} ({high_confidence/total_mappings*100:.1f}%)\")\n",
    "print(f\"   Medium confidence matches: {medium_confidence} ({medium_confidence/total_mappings*100:.1f}%)\")\n",
    "print(f\"   Low confidence matc hes: {low_confidence} ({low_confidence/total_mappings*100:.1f}%)\")\n",
    "print(f\"üìÅ File saved ‚Üí final_icd10_mapped_output_3.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
